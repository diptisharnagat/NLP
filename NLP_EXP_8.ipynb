{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuqLRacphGNJDMLkBX9bkL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diptisharnagat/NLP/blob/main/NLP_EXP_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bbJaIEBnZaVH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample data (context and senses)"
      ],
      "metadata": {
        "id": "F04rIiQRZydh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    ([\"The\", \"bank\", \"by\", \"the\", \"river\", \"is\", \"steep.\"], \"financial_institution\"),\n",
        "    ([\"I\", \"walked\", \"along\", \"the\", \"river\", \"bank\", \"yesterday.\"], \"river_bank\"),\n",
        "]"
      ],
      "metadata": {
        "id": "RgMsbP0nZ02U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a vocabulary"
      ],
      "metadata": {
        "id": "PmAoLcFjZ8Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(word for context, _ in data for word in context)\n",
        "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}"
      ],
      "metadata": {
        "id": "8RMPRAbNZ9UO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map sense labels to integers"
      ],
      "metadata": {
        "id": "oSplFW_7aD5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sense_labels = list(set(label for _, label in data))\n",
        "sense_to_idx = {sense: idx for idx, sense in enumerate(sense_labels)}\n",
        "idx_to_sense = {idx: sense for sense, idx in sense_to_idx.items()}"
      ],
      "metadata": {
        "id": "kDwwdC2naEt9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert data to tensors"
      ],
      "metadata": {
        "id": "-gj7gOI-aLpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_tensors = [(torch.tensor([word_to_idx[word] for word in context]), torch.tensor(sense_to_idx[sense])) for context, sense in data]"
      ],
      "metadata": {
        "id": "G75bK-k9aPL3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the LSTM-based WSD model\n"
      ],
      "metadata": {
        "id": "6HvaEyHWaYr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WSDModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, sense_count):\n",
        "        super(WSDModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, sense_count)\n",
        "\n",
        "    def forward(self, context):\n",
        "        embedded = self.embedding(context)\n",
        "        lstm_out, _ = self.lstm(embedded.view(len(context), 1, -1))\n",
        "        prediction = self.fc(lstm_out[-1])\n",
        "        return prediction\n"
      ],
      "metadata": {
        "id": "nz10PCiFaYPQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "cE6wZwckajU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 64\n",
        "sense_count = len(sense_labels)\n",
        "learning_rate = 0.001\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "zok1wLs6anMz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the model"
      ],
      "metadata": {
        "id": "7XCZWG1Xaz7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = WSDModel(vocab_size, embedding_dim, hidden_dim, sense_count)"
      ],
      "metadata": {
        "id": "I2zOMR5Ba07O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Define the loss function and optimizer"
      ],
      "metadata": {
        "id": "5e9jCQblbAtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "7FlkRt0jbFfR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop"
      ],
      "metadata": {
        "id": "su_PrZeIbKzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, criterion, optimizer, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for context, target_sense in data:\n",
        "            optimizer.zero_grad()\n",
        "            output = model(context)\n",
        "            loss = criterion(output, target_sense.unsqueeze(0))  # Add batch dimension to target\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data)}\")\n"
      ],
      "metadata": {
        "id": "pcLHmol4bO0j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "kadtjJM0bf98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, data_tensors, criterion, optimizer, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWg6r8x7blxc",
        "outputId": "3c448564-848f-46ca-d1e8-275457e51cc5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.7736735045909882\n",
            "Epoch 2/10, Loss: 0.6583276093006134\n",
            "Epoch 3/10, Loss: 0.5681799650192261\n",
            "Epoch 4/10, Loss: 0.48926404118537903\n",
            "Epoch 5/10, Loss: 0.41954848170280457\n",
            "Epoch 6/10, Loss: 0.35778510570526123\n",
            "Epoch 7/10, Loss: 0.3031216561794281\n",
            "Epoch 8/10, Loss: 0.25498469918966293\n",
            "Epoch 9/10, Loss: 0.21295592933893204\n",
            "Epoch 10/10, Loss: 0.1766686663031578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference (predict senses for new contexts)\n"
      ],
      "metadata": {
        "id": "kwam9QTAbrX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    new_context = [\"The\", \"bank\", \"charges\", \"high\", \"fees.\"]\n",
        "    new_context = torch.tensor([word_to_idx.get(word, 0) for word in new_context])\n",
        "    new_context = new_context.unsqueeze(0)  # Add batch dimension\n",
        "    predictions = model(new_context)\n",
        "    predicted_label = idx_to_sense[torch.argmax(predictions).item()]\n",
        "    print(f\"Predicted sense: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx5Z-P72bvTw",
        "outputId": "09dd2f4f-e5da-4530-8335-36f75e04c03b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sense: river_bank\n"
          ]
        }
      ]
    }
  ]
}